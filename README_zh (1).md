# ğŸ¦™ LaMaï¼šåŸºäºå‚…é‡Œå¶å·ç§¯çš„åˆ†è¾¨ç‡é²æ£’å¤§æ©ç å›¾åƒä¿®å¤

ä½œè€…ï¼šRoman Suvorov, Elizaveta Logacheva, Anton Mashikhin,
Anastasia Remizova, Arsenii Ashukha, Aleksei Silvestrov, Naejin Kong, Harshith Goka, Kiwoong Park, Victor Lempitsky.

<p align="center" "font-size:30px;">
  ğŸ”¥ğŸ”¥ğŸ”¥
  <br>
  <b>
LaMa èƒ½å¤Ÿå‡ºè‰²åœ°æ³›åŒ–åˆ°è¿œé«˜äºè®­ç»ƒåˆ†è¾¨ç‡ï¼ˆ256x256ï¼‰çš„æ›´é«˜åˆ†è¾¨ç‡ï¼ˆçº¦2kâ—ï¸ï¼‰ï¼Œå³ä½¿åœ¨å…·æœ‰æŒ‘æˆ˜æ€§çš„åœºæ™¯ä¸­ï¼ˆå¦‚å‘¨æœŸæ€§ç»“æ„çš„è¡¥å…¨ï¼‰ä¹Ÿèƒ½å–å¾—ä¼˜ç§€çš„æ•ˆæœã€‚</b>
</p>

[[é¡¹ç›®ä¸»é¡µ](https://advimman.github.io/lama-project/)] [[arXiv](https://arxiv.org/abs/2109.07161)] [[è¡¥å……ææ–™](https://ashukha.com/projects/lama_21/lama_supmat_2021.pdf)] [[BibTeX](https://senya-ashukha.github.io/projects/lama_21/paper.txt)] [[Casual GAN Papers æ‘˜è¦](https://www.casualganpapers.com/large-masks-fourier-convolutions-inpainting/LaMa-explained.html)]

<p align="center">
  <a href="https://colab.research.google.com/drive/15KTEIScUbVZtUP6w2tCDMVpE-b1r9pkZ?usp=drive_link">
  <img src="https://colab.research.google.com/assets/colab-badge.svg"/>
  </a>
      <br>
   åœ¨ Google Colab ä¸­è¯•ç”¨
  <br>
  æ‰€æœ‰ Yandex ä¸‹è½½é“¾æ¥å·²å¤±æ•ˆï¼Œæ‚¨å¯ä»¥ä»ä»¥ä¸‹åœ°å€ä¸‹è½½æ¨¡å‹ï¼šhttps://drive.google.com/drive/folders/1B2x7eQDgecTL0oh3LSIBDGj0fTxs6Ips?usp=sharing
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/senya-ashukha/senya-ashukha.github.io/master/projects/lama_21/ezgif-4-0db51df695a8.gif" />
</p>

<p align="center">
  <img src="https://raw.githubusercontent.com/senya-ashukha/senya-ashukha.github.io/master/projects/lama_21/gif_for_lightning_v1_white.gif" />
</p>



# LaMa ç›¸å…³å¼€å‘
ï¼ˆæ¬¢è¿é€šè¿‡åˆ›å»º issue åˆ†äº«æ‚¨çš„è®ºæ–‡ï¼‰
- https://github.com/geekyutao/Inpaint-Anything --- Inpaint Anythingï¼šSegment Anything ä¸å›¾åƒä¿®å¤çš„ç»“åˆ
<p align="center">
  <img src="https://raw.githubusercontent.com/geekyutao/Inpaint-Anything/main/example/MainFramework.png" />
</p>

- [ç‰¹å¾ç»†åŒ–ä»¥æ”¹è¿›é«˜åˆ†è¾¨ç‡å›¾åƒä¿®å¤](https://arxiv.org/abs/2206.13644) / [è§†é¢‘](https://www.youtube.com/watch?v=gEukhOheWgE) / ä»£ç  https://github.com/advimman/lama/pull/112 / ç”± Geomagical Labs æä¾›ï¼ˆ[geomagical.com](geomagical.com)ï¼‰
<p align="center">
  <img src="https://raw.githubusercontent.com/senya-ashukha/senya-ashukha.github.io/master/images/FeatureRefinement.png" />
</p>

# éå®˜æ–¹ç¬¬ä¸‰æ–¹åº”ç”¨ï¼š
ï¼ˆæ¬¢è¿é€šè¿‡åˆ›å»º issue åˆ†äº«æ‚¨çš„åº”ç”¨/å®ç°/æ¼”ç¤ºï¼‰

- https://github.com/enesmsahin/simple-lama-inpainting - ä¸€ä¸ªç®€å•çš„ LaMa ä¿®å¤ pip åŒ…ã€‚
- https://github.com/mallman/CoreMLaMa - Apple Core ML æ¨¡å‹æ ¼å¼
- [https://cleanup.pictures](https://cleanup.pictures/) - ä¸€ä¸ªç®€å•çš„äº¤äº’å¼ç‰©ä½“ç§»é™¤å·¥å…·ï¼Œç”± [@cyrildiagne](https://twitter.com/cyrildiagne) å¼€å‘
    - [lama-cleaner](https://github.com/Sanster/lama-cleaner)ï¼Œç”± [@Sanster](https://github.com/Sanster/lama-cleaner) å¼€å‘ï¼Œæ˜¯ [https://cleanup.pictures](https://cleanup.pictures/) çš„è‡ªæ‰˜ç®¡ç‰ˆæœ¬
- å·²é›†æˆåˆ° [Huggingface Spaces](https://huggingface.co/spaces)ï¼Œä½¿ç”¨ [Gradio](https://github.com/gradio-app/gradio)ã€‚æŸ¥çœ‹æ¼”ç¤ºï¼š[![Hugging Face Spaces](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/akhaliq/lama)ï¼Œç”± [@AK391](https://github.com/AK391) æä¾›
- Telegram æœºå™¨äºº [@MagicEraserBot](https://t.me/MagicEraserBot)ï¼Œç”± [@Moldoteck](https://github.com/Moldoteck) å¼€å‘ï¼Œ[ä»£ç ](https://github.com/Moldoteck/MagicEraser)
- [Auto-LaMa](https://github.com/andy971022/auto-lama) = DE:TR ç›®æ ‡æ£€æµ‹ + LaMa ä¿®å¤ï¼Œç”± [@andy971022](https://github.com/andy971022) å¼€å‘
- [LAMA-Magic-Eraser-Local](https://github.com/zhaoyun0071/LAMA-Magic-Eraser-Local) = åŸºäº PyQt5 æ„å»ºçš„ç‹¬ç«‹ä¿®å¤åº”ç”¨ç¨‹åºï¼Œç”± [@zhaoyun0071](https://github.com/zhaoyun0071) å¼€å‘
- [Hama](https://www.hama.app/) - ä½¿ç”¨æ™ºèƒ½ç”»ç¬”ç®€åŒ–æ©ç ç»˜åˆ¶çš„ç‰©ä½“ç§»é™¤å·¥å…·ã€‚
- [ModelScope](https://www.modelscope.cn/models/damo/cv_fft_inpainting_lama/summary) = ä¸­æ–‡æœ€å¤§çš„æ¨¡å‹ç¤¾åŒºï¼Œç”± [@chenbinghui1](https://github.com/chenbinghui1) æä¾›ã€‚
- [LaMa with MaskDINO](https://github.com/qwopqwop200/lama-with-maskdino) = MaskDINO ç›®æ ‡æ£€æµ‹ + LaMa ä¿®å¤ï¼ˆå«ç»†åŒ–ï¼‰ï¼Œç”± [@qwopqwop200](https://github.com/qwopqwop200) å¼€å‘ã€‚
- [CoreMLaMa](https://github.com/mallman/CoreMLaMa) - å°† Lama Cleaner ç§»æ¤çš„ LaMa è½¬æ¢ä¸º Apple Core ML æ¨¡å‹æ ¼å¼çš„è„šæœ¬ã€‚

# ç¯å¢ƒé…ç½®

â—ï¸â—ï¸â—ï¸ æ‰€æœ‰ Yandex ä¸‹è½½é“¾æ¥å·²å¤±æ•ˆï¼Œæ‚¨å¯ä»¥ä» [Google Drive](https://drive.google.com/drive/folders/1B2x7eQDgecTL0oh3LSIBDGj0fTxs6Ips?usp=sharing) ä¸‹è½½æ¨¡å‹ â—ï¸â—ï¸â—ï¸

å…‹éš†ä»“åº“ï¼š
`git clone https://github.com/advimman/lama.git`

æœ‰ä¸‰ç§ç¯å¢ƒé…ç½®æ–¹å¼ï¼š

1. Python virtualenvï¼š

    ```
    virtualenv inpenv --python=/usr/bin/python3
    source inpenv/bin/activate
    pip install torch==1.8.0 torchvision==0.9.0

    cd lama
    pip install -r requirements.txt
    ```

2. Conda

    ```
    % åœ¨ Linux ä¸Šå®‰è£… condaï¼Œå…¶ä»–æ“ä½œç³»ç»Ÿè¯·åœ¨ https://docs.conda.io/en/latest/miniconda.html ä¸‹è½½ miniconda
    wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
    bash Miniconda3-latest-Linux-x86_64.sh -b -p $HOME/miniconda
    $HOME/miniconda/bin/conda init bash

    cd lama
    conda env create -f conda_env.yml
    conda activate lama
    conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch -y
    pip install pytorch-lightning==1.2.9
    ```

3. Dockerï¼šæ— éœ€ä»»ä½•æ“ä½œ ğŸ‰ã€‚

# æ¨ç† <a name="prediction"></a>

è¿è¡Œï¼š
```
cd lama
export TORCH_HOME=$(pwd) && export PYTHONPATH=$(pwd)
```

**1. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹**

æœ€ä½³æ¨¡å‹ï¼ˆPlaces2, Places Challengeï¼‰ï¼š

```
curl -LJO https://huggingface.co/smartywu/big-lama/resolve/main/big-lama.zip
unzip big-lama.zip
```

æ‰€æœ‰æ¨¡å‹ï¼ˆPlaces å’Œ CelebA-HQï¼‰ï¼š

```
ä» [https://drive.google.com/drive/folders/1B2x7eQDgecTL0oh3LSIBDGj0fTxs6Ips?usp=drive_link] ä¸‹è½½
unzip lama-models.zip
```

**2. å‡†å¤‡å›¾åƒå’Œæ©ç **

ä¸‹è½½æµ‹è¯•å›¾åƒï¼š

```
unzip LaMa_test_images.zip
```
<details>
 <summary>æˆ–è€…è‡ªè¡Œå‡†å¤‡æ•°æ®ï¼š</summary>
1) åˆ›å»ºå‘½åæ ¼å¼ä¸º `[å›¾ç‰‡å]_maskXXX[å›¾ç‰‡åç¼€]` çš„æ©ç ï¼Œå¹¶å°†å›¾åƒå’Œæ©ç æ”¾åœ¨åŒä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ã€‚

- æ‚¨å¯ä»¥ä½¿ç”¨æ­¤[è„šæœ¬](https://github.com/advimman/lama/blob/main/bin/gen_mask_dataset.py)è¿›è¡Œéšæœºæ©ç ç”Ÿæˆã€‚
- æ£€æŸ¥æ–‡ä»¶æ ¼å¼ï¼š
    ```
    image1_mask001.png
    image1.png
    image2_mask001.png
    image2.png
    ```

2) åœ¨ `configs/prediction/default.yaml` ä¸­æŒ‡å®š `image_suffix`ï¼Œä¾‹å¦‚ `.png` æˆ– `.jpg` æˆ– `_input.jpg`ã€‚

</details>


**3. é¢„æµ‹**

åœ¨ä¸»æœºä¸Šï¼š

    python3 bin/predict.py model.path=$(pwd)/big-lama indir=$(pwd)/LaMa_test_images outdir=$(pwd)/output

**æˆ–è€…**åœ¨ Docker ä¸­

ä»¥ä¸‹å‘½ä»¤å°†ä» Docker Hub æ‹‰å– Docker é•œåƒå¹¶æ‰§è¡Œé¢„æµ‹è„šæœ¬ï¼š
```
bash docker/2_predict.sh $(pwd)/big-lama $(pwd)/LaMa_test_images $(pwd)/output device=cpu
```
Docker CUDAï¼š
```
bash docker/2_predict_with_gpu.sh $(pwd)/big-lama $(pwd)/LaMa_test_images $(pwd)/output
```

**4. å¸¦ç»†åŒ–çš„é¢„æµ‹**

åœ¨ä¸»æœºä¸Šï¼š

    python3 bin/predict.py refine=True model.path=$(pwd)/big-lama indir=$(pwd)/LaMa_test_images outdir=$(pwd)/output

# è®­ç»ƒä¸è¯„ä¼°

ç¡®ä¿å…ˆè¿è¡Œï¼š

```
cd lama
export TORCH_HOME=$(pwd) && export PYTHONPATH=$(pwd)
```

ç„¶åä¸‹è½½ _æ„ŸçŸ¥æŸå¤±_ æ‰€éœ€çš„æ¨¡å‹ï¼š

    mkdir -p ade20k/ade20k-resnet50dilated-ppm_deepsup/
    wget -P ade20k/ade20k-resnet50dilated-ppm_deepsup/ http://sceneparsing.csail.mit.edu/model/pytorch/ade20k-resnet50dilated-ppm_deepsup/encoder_epoch_20.pth


## Places

âš ï¸ æ³¨æ„ï¼šLaMa è®ºæ–‡ä¸­ Places æ•°æ®é›†çš„ FID/SSIM/LPIPS æŒ‡æ ‡å€¼æ˜¯åœ¨ä¸‹é¢è¯„ä¼°éƒ¨åˆ†ç”Ÿæˆçš„ 30000 å¼ å›¾åƒä¸Šè®¡ç®—å¾—åˆ°çš„ã€‚
æœ‰å…³è¯„ä¼°æ•°æ®çš„æ›´å¤šè¯¦æƒ…ï¼Œè¯·æŸ¥çœ‹ [[è¡¥å……ææ–™ç¬¬ 3 èŠ‚ï¼šæ•°æ®é›†åˆ’åˆ†](https://ashukha.com/projects/lama_21/lama_supmat_2021.pdf#subsection.3.1)]  âš ï¸

åœ¨ä¸»æœºä¸Šï¼š

    # ä» http://places2.csail.mit.edu/download.html ä¸‹è½½æ•°æ®
    # Places365-Standardï¼šä»é«˜åˆ†è¾¨ç‡å›¾åƒéƒ¨åˆ†ä¸‹è½½ Train(105GB)/Test(19GB)/Val(2.1GB)
    wget http://data.csail.mit.edu/places/places365/train_large_places365standard.tar
    wget http://data.csail.mit.edu/places/places365/val_large.tar
    wget http://data.csail.mit.edu/places/places365/test_large.tar

    # è§£å‹è®­ç»ƒ/æµ‹è¯•/éªŒè¯æ•°æ®å¹¶åˆ›å»º .yaml é…ç½®æ–‡ä»¶
    bash fetch_data/places_standard_train_prepare.sh
    bash fetch_data/places_standard_test_val_prepare.sh

    # ä¸ºæ¯ä¸ª epoch ç»“æŸæ—¶çš„æµ‹è¯•å’Œå¯è§†åŒ–é‡‡æ ·å›¾åƒ
    bash fetch_data/places_standard_test_val_sample.sh
    bash fetch_data/places_standard_test_val_gen_masks.sh

    # è¿è¡Œè®­ç»ƒ
    python3 bin/train.py -cn lama-fourier location=places_standard

    # ä¸ºäº†è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶æŠ¥å‘Šä¸è®ºæ–‡ä¸€è‡´çš„æŒ‡æ ‡ï¼Œ
    # æˆ‘ä»¬éœ€è¦é‡‡æ ·ä¹‹å‰æœªè§è¿‡çš„ 3 ä¸‡å¼ å›¾åƒå¹¶ä¸ºå®ƒä»¬ç”Ÿæˆæ©ç 
    bash fetch_data/places_standard_evaluation_prepare_data.sh

    # åœ¨ 256 å’Œ 512 çš„ç²—/ç»†/ä¸­ç­‰æ©ç ä¸Šè¿›è¡Œæ¨¡å‹æ¨ç†å¹¶è¿è¡Œè¯„ä¼°
    # ç¤ºä¾‹å¦‚ä¸‹ï¼š
    python3 bin/predict.py \
    model.path=$(pwd)/experiments/<user>_<date:time>_lama-fourier_/ \
    indir=$(pwd)/places_standard_dataset/evaluation/random_thick_512/ \
    outdir=$(pwd)/inference/random_thick_512 model.checkpoint=last.ckpt

    python3 bin/evaluate_predicts.py \
    $(pwd)/configs/eval2_gpu.yaml \
    $(pwd)/places_standard_dataset/evaluation/random_thick_512/ \
    $(pwd)/inference/random_thick_512 \
    $(pwd)/inference/random_thick_512_metrics.csv



Dockerï¼šå¾…å®Œæˆ

## CelebA
åœ¨ä¸»æœºä¸Šï¼š

    # ç¡®ä¿æ‚¨åœ¨ lama æ–‡ä»¶å¤¹ä¸­
    cd lama
    export TORCH_HOME=$(pwd) && export PYTHONPATH=$(pwd)

    # ä¸‹è½½ CelebA-HQ æ•°æ®é›†
    # ä» https://drive.google.com/drive/folders/11Vz0fqHS2rXDb5pprgTjpD7S2BAJhi1P ä¸‹è½½ data256x256.zip

    # è§£å‹å¹¶æ‹†åˆ†ä¸ºè®­ç»ƒ/æµ‹è¯•/å¯è§†åŒ–é›† & åˆ›å»ºé…ç½®æ–‡ä»¶
    bash fetch_data/celebahq_dataset_prepare.sh

    # ä¸ºæ¯ä¸ª epoch ç»“æŸæ—¶çš„æµ‹è¯•å’Œå¯è§†åŒ–æµ‹è¯•ç”Ÿæˆæ©ç 
    bash fetch_data/celebahq_gen_masks.sh

    # è¿è¡Œè®­ç»ƒ
    python3 bin/train.py -cn lama-fourier-celeba data.batch_size=10

    # åœ¨ 256 çš„ç²—/ç»†/ä¸­ç­‰æ©ç ä¸Šè¿›è¡Œæ¨¡å‹æ¨ç†å¹¶è¿è¡Œè¯„ä¼°
    # ç¤ºä¾‹å¦‚ä¸‹ï¼š
    python3 bin/predict.py \
    model.path=$(pwd)/experiments/<user>_<date:time>_lama-fourier-celeba_/ \
    indir=$(pwd)/celeba-hq-dataset/visual_test_256/random_thick_256/ \
    outdir=$(pwd)/inference/celeba_random_thick_256 model.checkpoint=last.ckpt


Dockerï¼šå¾…å®Œæˆ

## Places Challenge

åœ¨ä¸»æœºä¸Šï¼š

    # æ­¤è„šæœ¬å¹¶è¡Œä¸‹è½½å¤šä¸ª .tar æ–‡ä»¶å¹¶è§£å‹
    # Places365-Challengeï¼šä»é«˜åˆ†è¾¨ç‡å›¾åƒä¸‹è½½ Train(476GB)ï¼ˆç”¨äºè®­ç»ƒ Big-Lamaï¼‰
    bash places_challenge_train_download.sh

    å¾…å®Œæˆï¼šå‡†å¤‡
    å¾…å®Œæˆï¼šè®­ç»ƒ
    å¾…å®Œæˆï¼šè¯„ä¼°

Dockerï¼šå¾…å®Œæˆ

## åˆ›å»ºè‡ªå®šä¹‰æ•°æ®

è¯·æŸ¥çœ‹ CelebAHQ éƒ¨åˆ†çš„æ•°æ®å‡†å¤‡å’Œæ©ç ç”Ÿæˆ bash è„šæœ¬ï¼Œ
å¦‚æœæ‚¨åœ¨ä»¥ä¸‹æŸä¸ªæ­¥éª¤ä¸­é‡åˆ°å›°éš¾ã€‚


åœ¨ä¸»æœºä¸Šï¼š

    # ç¡®ä¿æ‚¨åœ¨ lama æ–‡ä»¶å¤¹ä¸­
    cd lama
    export TORCH_HOME=$(pwd) && export PYTHONPATH=$(pwd)

    # æ‚¨éœ€è¦å‡†å¤‡ä»¥ä¸‹å›¾åƒæ–‡ä»¶å¤¹ï¼š
    $ ls my_dataset
    train
    val_source # 2000 å¼ æˆ–æ›´å¤šå›¾åƒ
    visual_test_source # 100 å¼ æˆ–æ›´å¤šå›¾åƒ
    eval_source # 2000 å¼ æˆ–æ›´å¤šå›¾åƒ

    # LaMa åœ¨è®­ç»ƒæ—¶åŠ¨æ€ç”Ÿæˆéšæœºæ©ç ï¼Œ
    # ä½†æµ‹è¯•å’Œå¯è§†åŒ–æµ‹è¯•éœ€è¦å›ºå®šçš„æ©ç ä»¥ç¡®ä¿è¯„ä¼°ä¸€è‡´æ€§ã€‚

    # å‡è®¾æˆ‘ä»¬æƒ³åœ¨ 512x512 çš„éªŒè¯æ•°æ®é›†ä¸Šä½¿ç”¨ç²—/ç»†/ä¸­ç­‰æ©ç è¯„ä¼°å’Œé€‰æ‹©æœ€ä½³æ¨¡å‹
    # å¹¶ä¸”æ‚¨çš„å›¾åƒæ‰©å±•åä¸º .jpgï¼š

    python3 bin/gen_mask_dataset.py \
    $(pwd)/configs/data_gen/random_<size>_512.yaml \ # thick, thin, medium
    my_dataset/val_source/ \
    my_dataset/val/random_<size>_512.yaml \# thick, thin, medium
    --ext jpg

    # æ©ç ç”Ÿæˆå™¨å°†ï¼š
    # 1. è°ƒæ•´å¤§å°å¹¶è£å‰ªéªŒè¯å›¾åƒï¼Œä¿å­˜ä¸º .png
    # 2. ç”Ÿæˆæ©ç 

    ls my_dataset/val/random_medium_512/
    image1_crop000_mask000.png
    image1_crop000.png
    image2_crop000_mask000.png
    image2_crop000.png
    ...

    # ä¸º visual_test æ–‡ä»¶å¤¹ç”Ÿæˆç²—/ç»†/ä¸­ç­‰æ©ç ï¼š

    python3 bin/gen_mask_dataset.py \
    $(pwd)/configs/data_gen/random_<size>_512.yaml \  #thick, thin, medium
    my_dataset/visual_test_source/ \
    my_dataset/visual_test/random_<size>_512/ \ #thick, thin, medium
    --ext jpg


    ls my_dataset/visual_test/random_thick_512/
    image1_crop000_mask000.png
    image1_crop000.png
    image2_crop000_mask000.png
    image2_crop000.png
    ...

    # å¯¹ eval_source å›¾åƒæ–‡ä»¶å¤¹æ‰§è¡Œç›¸åŒæ“ä½œï¼š

    python3 bin/gen_mask_dataset.py \
    $(pwd)/configs/data_gen/random_<size>_512.yaml \  #thick, thin, medium
    my_dataset/eval_source/ \
    my_dataset/eval/random_<size>_512/ \ #thick, thin, medium
    --ext jpg



    # ç”Ÿæˆå®šä½è¿™äº›æ–‡ä»¶å¤¹çš„é…ç½®æ–‡ä»¶ï¼š

    touch my_dataset.yaml
    echo "data_root_dir: $(pwd)/my_dataset/" >> my_dataset.yaml
    echo "out_root_dir: $(pwd)/experiments/" >> my_dataset.yaml
    echo "tb_dir: $(pwd)/tb_logs/" >> my_dataset.yaml
    mv my_dataset.yaml ${PWD}/configs/training/location/


    # æ£€æŸ¥æ•°æ®é…ç½®ä¸ my_dataset æ–‡ä»¶å¤¹ç»“æ„çš„ä¸€è‡´æ€§ï¼š
    $ cat ${PWD}/configs/training/data/abl-04-256-mh-dist
    ...
    train:
      indir: ${location.data_root_dir}/train
      ...
    val:
      indir: ${location.data_root_dir}/val
      img_suffix: .png
    visual_test:
      indir: ${location.data_root_dir}/visual_test
      img_suffix: .png


    # è¿è¡Œè®­ç»ƒ
    python3 bin/train.py -cn lama-fourier location=my_dataset data.batch_size=10

    # è¯„ä¼°ï¼šLaMa è®­ç»ƒè¿‡ç¨‹ä¼šæ ¹æ® my_dataset/val/ ä¸Šçš„åˆ†æ•°
    # æŒ‘é€‰æœ€ä½³çš„å‡ ä¸ªæ¨¡å‹

    # è¦åœ¨ä¹‹å‰æœªè§è¿‡çš„ my_dataset/eval ä¸Šè¯„ä¼°æ‚¨çš„æœ€ä½³æ¨¡å‹ä¹‹ä¸€ï¼ˆä¾‹å¦‚ epoch=32ï¼‰
    # å¯¹ç²—ã€ç»†å’Œä¸­ç­‰æ©ç æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š

    # æ¨ç†ï¼š
    python3 bin/predict.py \
    model.path=$(pwd)/experiments/<user>_<date:time>_lama-fourier_/ \
    indir=$(pwd)/my_dataset/eval/random_<size>_512/ \
    outdir=$(pwd)/inference/my_dataset/random_<size>_512 \
    model.checkpoint=epoch32.ckpt

    # æŒ‡æ ‡è®¡ç®—ï¼š
    python3 bin/evaluate_predicts.py \
    $(pwd)/configs/eval2_gpu.yaml \
    $(pwd)/my_dataset/eval/random_<size>_512/ \
    $(pwd)/inference/my_dataset/random_<size>_512 \
    $(pwd)/inference/my_dataset/random_<size>_512_metrics.csv


**æˆ–è€…**åœ¨ Docker ä¸­ï¼š

    å¾…å®Œæˆï¼šè®­ç»ƒ
    å¾…å®Œæˆï¼šè¯„ä¼°

# æç¤º

### ç”Ÿæˆä¸åŒç±»å‹çš„æ©ç 
ä»¥ä¸‹å‘½ä»¤å°†æ‰§è¡Œä¸€ä¸ªç”Ÿæˆéšæœºæ©ç çš„è„šæœ¬ã€‚

    bash docker/1_generate_masks_from_raw_images.sh \
        configs/data_gen/random_medium_512.yaml \
        /è¾“å…¥å›¾åƒç›®å½• \
        /å­˜å‚¨å›¾åƒå’Œæ©ç çš„ç›®å½• \
        --ext png

æµ‹è¯•æ•°æ®ç”Ÿæˆå‘½ä»¤ä¼šä»¥é€‚åˆ[é¢„æµ‹](#prediction)çš„æ ¼å¼å­˜å‚¨å›¾åƒã€‚

ä¸‹è¡¨æè¿°äº†æˆ‘ä»¬ç”¨æ¥ç”Ÿæˆè®ºæ–‡ä¸­ä¸åŒæµ‹è¯•é›†çš„é…ç½®ã€‚
è¯·æ³¨æ„ï¼Œæˆ‘ä»¬*æ²¡æœ‰å›ºå®šéšæœºç§å­*ï¼Œå› æ­¤æ¯æ¬¡ç»“æœä¼šç•¥æœ‰ä¸åŒã€‚

|        | Places 512x512         | CelebA 256x256         |
|--------|------------------------|------------------------|
| çª„æ©ç  | random_thin_512.yaml   | random_thin_256.yaml   |
| ä¸­ç­‰æ©ç  | random_medium_512.yaml | random_medium_256.yaml |
| å®½æ©ç  | random_thick_512.yaml  | random_thick_256.yaml  |

æ‚¨å¯ä»¥éšæ„æ›´æ”¹é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆç¬¬ 1 ä¸ªå‚æ•°ï¼‰ä¸º `configs/data_gen` ä¸­çš„ä»»ä½•å…¶ä»–é…ç½®ï¼Œ
æˆ–è‡ªè¡Œè°ƒæ•´é…ç½®æ–‡ä»¶ã€‚

### è¦†ç›–é…ç½®ä¸­çš„å‚æ•°
æ‚¨è¿˜å¯ä»¥åƒè¿™æ ·è¦†ç›–é…ç½®ä¸­çš„å‚æ•°ï¼š

    python3 bin/train.py -cn <config> data.batch_size=10 run_title=my-title

å…¶ä¸­ .yaml æ–‡ä»¶æ‰©å±•åå¯çœç•¥

### æ¨¡å‹é€‰é¡¹
è®ºæ–‡ä¸­æ¨¡å‹çš„é…ç½®åç§°ï¼ˆæ›¿æ¢åˆ°è®­ç»ƒå‘½ä»¤ä¸­ï¼‰ï¼š

    * big-lama
    * big-lama-regular
    * lama-fourier
    * lama-regular
    * lama_small_train_masks

å®ƒä»¬ä½äº configs/training/ æ–‡ä»¶å¤¹ä¸­

### é“¾æ¥
- æ‰€æœ‰æ•°æ®ï¼ˆæ¨¡å‹ã€æµ‹è¯•å›¾åƒç­‰ï¼‰https://disk.yandex.ru/d/AmdeG-bIjmvSug
- è®ºæ–‡ä¸­çš„æµ‹è¯•å›¾åƒ https://disk.yandex.ru/d/xKQJZeVRk5vLlQ
- é¢„è®­ç»ƒæ¨¡å‹ https://disk.yandex.ru/d/EgqaSnLohjuzAg
- æ„ŸçŸ¥æŸå¤±æ¨¡å‹ https://disk.yandex.ru/d/ncVmQlmT_kTemQ
- æˆ‘ä»¬çš„è®­ç»ƒæ—¥å¿—å¯åœ¨æ­¤æŸ¥çœ‹ https://disk.yandex.ru/d/9Bt1wNSDS4jDkQ


### è®­ç»ƒæ—¶é—´ä¸èµ„æº

å¾…å®Œæˆ

## è‡´è°¢

* åˆ†å‰²ä»£ç å’Œæ¨¡å‹æ¥è‡ª [CSAILVision](https://github.com/CSAILVision/semantic-segmentation-pytorch)ã€‚
* LPIPS æŒ‡æ ‡æ¥è‡ª [richzhang](https://github.com/richzhang/PerceptualSimilarity)
* SSIM æ¥è‡ª [Po-Hsun-Su](https://github.com/Po-Hsun-Su/pytorch-ssim)
* FID æ¥è‡ª [mseitzer](https://github.com/mseitzer/pytorch-fid)

## å¼•ç”¨
å¦‚æœæ‚¨è§‰å¾—æ­¤ä»£ç æœ‰å¸®åŠ©ï¼Œè¯·è€ƒè™‘å¼•ç”¨ï¼š
```
@article{suvorov2021resolution,
  title={Resolution-robust Large Mask Inpainting with Fourier Convolutions},
  author={Suvorov, Roman and Logacheva, Elizaveta and Mashikhin, Anton and Remizova, Anastasia and Ashukha, Arsenii and Silvestrov, Aleksei and Kong, Naejin and Goka, Harshith and Park, Kiwoong and Lempitsky, Victor},
  journal={arXiv preprint arXiv:2109.07161},
  year={2021}
}
```
